<!-- @format -->

## SC1005 Mini-Project: Toxic Comment Classification Challenge

## About

This is a Mini-Project for SC1005 (Introduction to Data Science and Artificial Intelligence) which focuses on Toxic Comment Classification Challenge

![image](https://d19gb5k9ejx8w0.cloudfront.net/uploads/2021/07/29222440/Cyberbullying_featured_image.jpg)

## Contributors(PT1 Team 3)

- [@chenxe](https://github.com/chenxe) CHEN XUEER
- [@SuSuTun25](https://github.com/SusuTun25) SUSU TUN

## Objective

To develop a machine learning model that accurately detects and classifies toxic or offensive content in the text for further action can be useful in various applications, such as social media moderation, content filtering, and online harassment prevention. Additionally, the model can provide feedback to users who use inappropriate language, encouraging them to change their behavior and contribute to a more positive online conversation. Basically, it aims to promote a more inclusive, respectful, and healthy online community where everyone can feel safe to express their opinions without fear of being harassed or insulted.

## Suggestions

Addressing toxic behavior requires a multifaceted approach that involves:

- Education on appropriate online behavior
- Community Moderation encourage community members to report toxic behavior and have a dedicated team to review and address those reports
- Empower victims of toxic behavior to speak out and take action. Provide them with the necessary tools and resources to report, block, and seek help
- Platform policies clearly communicated to user that prohibit toxic behavior, hate speech, and harassment
- Develop and implement machine learning algorithms and other technology solutions to identify and address toxic behavior in real-time

## Conclusion

In conclusion, the development of a toxic comment classifier is a crucial step in creating a safer and more respectful online environment. The project involved the use of machine learning algorithms to train a model that could accurately classify comments as toxic or non-toxic. Through the use of natural language processing techniques, the model was able to analyze the language used in comments and make predictions about their toxicity.

The project required the acquisition and preprocessing of a large dataset of comments, as well as the selection and training of appropriate machine learning algorithms. The resulting toxic comment classifier showed promising results in accurately identifying toxic comments, which can be used to identify and address toxic behavior online.

However, it is important to note that this project is just one step in addressing the larger issue of toxic behavior online. The model is not perfect and may still misclassify certain comments.

## What did we learn from this project?

- Natural Language Processing Techniques
- Neural Networks
- Bidirectional LSTM
- Collaborating using GitHub
- other new packages like tensorflow,gradio

## Libraries

- Pandas
- Numpy
- Seaborn
- matplotlib
- tensorflow
- textblob
- networkx
- collections
- nltk
- gradio

## Model Used

- Neural Network
- Bidirectional LSTM
