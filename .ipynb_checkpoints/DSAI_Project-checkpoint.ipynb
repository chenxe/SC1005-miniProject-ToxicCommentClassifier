{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8d7I24VRfW9"
   },
   "source": [
    "# SC1015 DSAI Project:\n",
    "### [Toxic Comment Classification Challenge Dataset from Kaggle](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "le_6JuEIT0Sz"
   },
   "outputs": [],
   "source": [
    "## Import Relevant Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from textblob import TextBlob,Word\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cdq7xVgTpXe"
   },
   "source": [
    "## Setup : Import the Dataset\n",
    "The dataset `train.csv` is in CSV format, hence we use the `read_csv` function from Pandas, and take a quick look at the data using the head function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "TB4ldRVSbHdA",
    "outputId": "8bb68e9d-d0c9-4fe6-f7f4-2a6773bb790d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entries with all 0 under the 6 categories are considered as non-toxic.</br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yH6gM-KieG8T",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of object type in the dataset using the .info() method\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check null value in dataset, need to clean dataset if there is missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q5QUmhCAeN_5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the null values of the df\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing steps - remove numbers, capital letters, punctuation, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r Why the edits made under my user...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r More\\r I can't make any real suggestions o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r Why the edits made under my user...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r More\\r I can't make any real suggestions o...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Remove all '\\n' in the string and replace it with a space\n",
    "rm_breakline = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "\n",
    "# Remove all non-ascii characters \n",
    "rm_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n",
    "\n",
    "# Apply all the lambda functions wrote previously through .map on the comments column\n",
    "df['comment_text'] = df['comment_text'].map(rm_breakline).map(rm_non_ascii)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure columns: toxic, severe_toxic, obscene, threat, insult, and identity_hate have no other value other than 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Value\n",
      "toxic            1\n",
      "severe_toxic     1\n",
      "obscene          1\n",
      "threat           1\n",
      "insult           1\n",
      "identity_hate    1\n",
      "dtype: int64\n",
      "\n",
      "Min Value\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n",
      "\n",
      "Distinct Value of all column\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Value\")\n",
    "#find the max value to every column\n",
    "print(df[df.columns[2:8]].max())\n",
    "print(\"\\nMin Value\")\n",
    "#find the min value to every column\n",
    "print(df[df.columns[2:8]].min())\n",
    "#find the distinct value of every column\n",
    "print(\"\\nDistinct Value of all column\")\n",
    "print(pd.unique(df[df.columns[2:8]].values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of rows that have 1 in more that 1 category eg. comment id:0002bcb3da6cb337 under toxic,severe toxic,obscene,insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.iloc[:, 2:8] == 1).sum(axis=1) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Comment into Sentiment\n",
    " - Negative\n",
    " - Neutral\n",
    " - Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(x):\n",
    "    if TextBlob(x).sentiment[0] > 0.25:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def sentiment(x):\n",
    "    cols_to_check = df.columns[2:8]\n",
    "    if any(df.loc[x.name, cols_to_check] == 1):\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return polarity(x['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.apply(sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of Comment falls under \n",
    "- Sentiment: Negative, Neutral and Positive\n",
    "- comment classifier: toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df['sentiment'].value_counts()\n",
    "perc = df['sentiment'].value_counts(normalize=True)\n",
    "pd.DataFrame({'counts': count, 'percentages': perc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "categories = df['sentiment'].unique().tolist()\n",
    "values = df['sentiment'].value_counts().tolist()\n",
    "\n",
    "# calculate percentages\n",
    "total = sum(values)\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(categories, values)\n",
    "ax.set_title('Comment Count vs. Sentiment')\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Comment Count')\n",
    "\n",
    "# add percentages as annotations above each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(i, value), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Comment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[2:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of rows that have 1 in more that 1 category eg. comment id:0002bcb3da6cb337 under toxic,severe toxic,obscene,insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.iloc[:, 2:8] == 1).sum(axis=1) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df[df.columns[2:8]].sum()\n",
    "perc = df[df.columns[2:8]].sum()/len(df[df['sentiment']=='Negative'])\n",
    "pd.DataFrame({'counts': count, 'percentages': perc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "categories = df.columns[2:8].tolist()\n",
    "values = df[df.columns[2:8]].sum().tolist()\n",
    "\n",
    "# calculate percentages\n",
    "total = len(df[df['sentiment']=='Negative'])\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the horizontal bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(categories, values)\n",
    "ax.set_title('Negetive Comment Count vs. Sentiment')\n",
    "ax.set_xlabel('Comment Count')\n",
    "ax.set_ylabel('Sentiment')\n",
    "\n",
    "# add percentages as annotations to the right of each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(value, i), ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of comment fall under\n",
    "- Sentiment: Negative, Neutral and Positive\n",
    "- comment classifier: toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add word_count column\n",
    "df['word_count'] = df['comment_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=df['sentiment'].unique().tolist()\n",
    "category_word_count= []\n",
    "for i in categories:\n",
    "    category_word_count.append(int(df.loc[df['sentiment'] == i, ['word_count']].sum()))\n",
    "\n",
    "pd.DataFrame({'categories': categories, 'word_count': category_word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = category_word_count\n",
    "\n",
    "# calculate percentages\n",
    "total = sum(values)\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(categories, values)\n",
    "ax.set_title('Word Count vs. Sentiment')\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Comment Word Count')\n",
    "\n",
    "# add percentages as annotations above each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(i, value), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Comment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=df.columns[2:8].tolist()\n",
    "category_word_count= []\n",
    "for i in categories:\n",
    "    category_word_count.append(int(df.loc[df[i] == 1, ['word_count']].sum()))\n",
    "\n",
    "pd.DataFrame({'categories': categories, 'word_count': category_word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "values = category_word_count\n",
    "\n",
    "# calculate percentages\n",
    "total = int(df.loc[df['sentiment'] == 'Negative', ['word_count']].sum())\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the horizontal bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(categories, values)\n",
    "ax.set_title('Word Count vs. Negative Sentiment')\n",
    "ax.set_xlabel('Comment Word Count')\n",
    "ax.set_ylabel('Sentiment')\n",
    "\n",
    "# add percentages as annotations to the right of each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(value, i), ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Length of comment\n",
    "- Sentiment: Negative, Neutral and Positive\n",
    "- comment classifier: toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=df['sentiment'].unique().tolist()\n",
    "category_word_count= []\n",
    "for i in categories:\n",
    "    category_word_count.append(round(int(df.loc[df['sentiment'] == i, ['word_count']].sum())/len(df.loc[df['sentiment'] == i]),2))\n",
    "\n",
    "pd.DataFrame({'categories': categories, ' word_count': category_word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average word count for all sentiment\n",
    "round(df['word_count'].sum()/len(df),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = category_word_count\n",
    "\n",
    "# calculate percentages\n",
    "total = df['word_count'].sum()/len(df)\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(categories, values)\n",
    "ax.set_title('Word Count vs. Sentiment')\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Comment Word Count')\n",
    "\n",
    "# add percentages as annotations above each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(i, value), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Comment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=df.columns[2:8].tolist()\n",
    "category_word_count= []\n",
    "for i in categories:\n",
    "    category_word_count.append(round(int(df.loc[df[i] == 1, ['word_count']].sum())/len(df.loc[df[i] == 1]),2))\n",
    "\n",
    "pd.DataFrame({'categories': categories, 'word_count': category_word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average word count for negative comment\n",
    "round(int(df.loc[df['sentiment'] == 'Negative', ['word_count']].sum())/len(df.loc[df['sentiment'] == 'Negative']),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "values = category_word_count\n",
    "\n",
    "# calculate percentages\n",
    "total = int(df.loc[df['sentiment'] == 'Negative', ['word_count']].sum())/len(df.loc[df['sentiment'] == 'Negative'])\n",
    "percentages = [(value / total) * 100 for value in values]\n",
    "\n",
    "# plot the horizontal bar graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(categories, values)\n",
    "ax.set_title('Average Word Count vs. Negative Sentiment')\n",
    "ax.set_xlabel('Average Comment Word Count')\n",
    "ax.set_ylabel('Sentiment')\n",
    "\n",
    "# add percentages as annotations to the right of each bar\n",
    "for i, value in enumerate(values):\n",
    "    ax.annotate(f'{value} ({percentages[i]:.2f}%)', xy=(value, i), ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud\n",
    "- Sentiment: Negative, Neutral and Positive\n",
    "- comment classifier: toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into 6 categories: Positive, Neutral, Negative\n",
    "df_positive = df.loc[df['sentiment'] == 'Positive', ['id', 'comment_text', 'sentiment']]\n",
    "df_neutral = df.loc[df['sentiment'] == 'Neutral', ['id', 'comment_text', 'sentiment']]\n",
    "df_negative = df.loc[df['sentiment'] == 'Negative', ['id', 'comment_text', 'sentiment']]\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def wordcloud(df, label):\n",
    "    subset=df\n",
    "    text=subset.comment_text.values\n",
    "    wc= WordCloud(background_color=\"black\",max_words=4000)\n",
    "\n",
    "    wc.generate(\" \".join(text))\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(221)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Words frequented in {}\".format(label), fontsize=20)\n",
    "    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df=[df_positive,df_neutral,df_negative]\n",
    "\n",
    "for i in range(len(category_df)):\n",
    "    wordcloud(category_df[i],','.join(category_df[i]['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Comment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into 6 categories: toxic, severe_toxic, obscene, threat, insult, and identity_hate. df_category stucture = {id,comment,categotry}\n",
    "df_toxic = df.loc[:,['id','comment_text','toxic']]\n",
    "df_severe = df.loc[:,['id','comment_text','severe_toxic']]\n",
    "df_obscene = df.loc[:,['id','comment_text','obscene']]\n",
    "df_threat = df.loc[:,['id','comment_text','threat']]\n",
    "df_insult = df.loc[:,['id','comment_text','insult']]\n",
    "df_hate = df.loc[:,['id','comment_text','identity_hate']]\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def wordcloud(df, label):\n",
    "    # Print only rows where the toxic category label value is 1 (ie. the comment is toxic)\n",
    "    subset=df[df[label]==1]\n",
    "    text=subset.comment_text.values\n",
    "    wc= WordCloud(background_color=\"black\",max_words=4000)\n",
    "\n",
    "    wc.generate(\" \".join(text))\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(221)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Words frequented in {}\".format(label), fontsize=20)\n",
    "    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df=[df_toxic,df_severe,df_obscene,df_threat,df_insult,df_hate]\n",
    "\n",
    "for i in range(len(category_df)):\n",
    "    wordcloud(category_df[i],category_df[i].columns[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network graph: Frequently used words in all category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter data to only include comments labeled as all categories\n",
    "all_categories_data = df[(df['toxic'] == 1) &\n",
    "                         (df['severe_toxic'] == 1) &\n",
    "                         (df['obscene'] == 1) &\n",
    "                         (df['threat'] == 1) &\n",
    "                         (df['insult'] == 1) &\n",
    "                         (df['identity_hate'] == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the stop words for English\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Add stop words to the existing exclude_words list\n",
    "exclude_words =  stop_words\n",
    "\n",
    "# Remove duplicates from the list\n",
    "exclude_words = list(set(exclude_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(all_categories_data['comment_text'])\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "# Calculate the frequency of each word\n",
    "word_freq = Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 50 most common words\n",
    "top_words = [word[0] for word in word_freq.most_common(50)]\n",
    "\n",
    "# Create a dictionary to store co-occurrence counts\n",
    "co_occur_dict = {}\n",
    "\n",
    "# Loop through each comment in the data\n",
    "for comment in all_categories_data['comment_text']:\n",
    "    # Split the comment into individual words\n",
    "    comment_words = comment.split()\n",
    "    # Loop through each pair of words in the comment\n",
    "    for i in range(len(comment_words)):\n",
    "        for j in range(i+1, len(comment_words)):\n",
    "            # Check if both words are in the top 50 most common words\n",
    "            if comment_words[i] in top_words and comment_words[j] in top_words:\n",
    "                # Increment the co-occurrence count for the pair of words\n",
    "                pair = tuple(sorted([comment_words[i], comment_words[j]]))\n",
    "                if pair in co_occur_dict:\n",
    "                    co_occur_dict[pair] += 1\n",
    "                else:\n",
    "                    co_occur_dict[pair] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for word in top_words:\n",
    "    G.add_node(word)\n",
    "\n",
    "# Add edges\n",
    "for pair, weight in co_occur_dict.items():\n",
    "    node1, node2 = pair\n",
    "    G.add_edge(node1, node2, weight=weight)\n",
    "\n",
    "# Set the positions of the nodes using the spring layout algorithm\n",
    "pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size=1000, node_color='lightblue', ax=ax)\n",
    "nx.draw_networkx_edges(G, pos, width=1, alpha=0.5, ax=ax)\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif', ax=ax)\n",
    "\n",
    "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G, pos, edge_labels=edge_labels, font_size=12, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Top 50 Most Common Words')\n",
    "ax.set_ylabel('Co-Occurrence')\n",
    "ax.set_title('Co-Occurrence of Top 50 Most Common Words in All Categories')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words that uniquely exist in\n",
    "- Sentiment: Negative, Neutral and Positive\n",
    "- comment classifier: toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common words that uniquely exist in toxic only\n",
    "data_positive = df.loc[df['sentiment'] == 'Positive']\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_positive['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Positive Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common words that uniquely exist in toxic only\n",
    "data_neutral = df.loc[df['sentiment'] == 'Neutral']\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_neutral['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Neutral Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common words that uniquely exist in toxic only\n",
    "data_negative = df.loc[df['sentiment'] == 'Negative']\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_negative['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Neutral Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Comment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common words that uniquely exist in toxic only\n",
    "data_toxic = df[(df['toxic'] == 1) &\n",
    "                (df['severe_toxic'] == 0) &\n",
    "                (df['obscene'] == 0) &\n",
    "                (df['threat'] == 0) &\n",
    "                (df['insult'] == 0) &\n",
    "                (df['identity_hate'] == 0)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_toxic['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Toxic Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common words that uniquely exist in severe toxic only\n",
    "data_severe_toxic = df[(df['toxic'] == 0) &\n",
    "                       (df['severe_toxic'] == 1) &\n",
    "                       (df['obscene'] == 0) &\n",
    "                       (df['threat'] == 0) &\n",
    "                       (df['insult'] == 0) &\n",
    "                       (df['identity_hate'] == 0)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_severe_toxic['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 20 words and their frequencies\n",
    "top_words = word_counts.most_common(20)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 20 Words in Severe Toxic Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common obscene words that dont fall under other category\n",
    "data_obscene = df[(df['toxic'] == 0) &\n",
    "                  (df['severe_toxic'] == 0) &\n",
    "                  (df['obscene'] == 1) &\n",
    "                  (df['threat'] == 0) &\n",
    "                  (df['insult'] == 0) &\n",
    "                  (df['identity_hate'] == 0)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_obscene['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Obscene Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only include comments labeled in threat only \n",
    "data_threat = df[(df['toxic'] == 0) &\n",
    "                 (df['severe_toxic'] == 0) &\n",
    "                 (df['obscene'] == 0) &\n",
    "                 (df['threat'] == 1) &\n",
    "                 (df['insult'] == 0) &\n",
    "                 (df['identity_hate'] == 0)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_threat['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Threat Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only include comments labeled in identity only\n",
    "data_identity_hate = df[(df['toxic'] == 0) &\n",
    "                        (df['severe_toxic'] == 0) &\n",
    "                        (df['obscene'] == 0) &\n",
    "                        (df['threat'] == 0) &\n",
    "                        (df['insult'] == 0) &\n",
    "                        (df['identity_hate'] == 1)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_identity_hate['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Identity Hate Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only include comments labeled in insult only\n",
    "data_insult = df[(df['toxic'] == 0) &\n",
    "                 (df['severe_toxic'] == 0) &\n",
    "                 (df['obscene'] == 0) &\n",
    "                 (df['threat'] == 0) &\n",
    "                 (df['insult'] == 1) &\n",
    "                 (df['identity_hate'] == 0)]\n",
    "\n",
    "\n",
    "# Concatenate all comments into a single string\n",
    "all_comments = ' '.join(data_insult['comment_text'])\n",
    "\n",
    "\n",
    "# Split the string into individual words, excluding words in the exclusion list\n",
    "words = [word for word in all_comments.split() if word.lower()\n",
    "         not in exclude_words]\n",
    "\n",
    "\n",
    "# Count the frequency of each word in the list\n",
    "word_counts = Counter(words)\n",
    "\n",
    "\n",
    "# Get the top 30 words and their frequencies\n",
    "top_words = word_counts.most_common(30)\n",
    "labels = [word for word, count in top_words]\n",
    "counts = [count for word, count in top_words]\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Top 30 Words in Insult Only\")\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurance matrix to show which categories go together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that only contains the category columns\n",
    "categories_df = df[['toxic', 'severe_toxic',\n",
    "                    'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = categories_df.corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texttectorization map text to interger sequence and dataset preparation for machine Learning\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:8]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Number of words in the comment_text < TextVectorization output_sequence_length\n",
    "max(X.apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in the vocab\n",
    "MAX_WORDS = 200000 \n",
    "\n",
    "# initialize TextVectorizer\n",
    "vectorizer = TextVectorization(max_tokens=MAX_WORDS,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)\n",
    "\n",
    "# map all comment text words to integer sequence\n",
    "vectorized_text = vectorizer(X.values)\n",
    "\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorflow data pipeline\n",
    "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 70% Test 10% valuate 20%\n",
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding   #layers to build up deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN model\n",
    "model = Sequential()\n",
    "# Create the embedding layer \n",
    "model.add(Embedding(MAX_WORDS+1, 32))\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "# Feature extractor Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Final layer map to 6 classifier\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs=3, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck!')\n",
    "res = model.predict(np.expand_dims(input_text,0))\n",
    "\n",
    "(res > 0.5).astype(int)\n",
    "#toxic\tsevere_toxic    obscene     threat\tinsult\tidentity_hate    \n",
    "# [1    , 0             , 1         ,0      ,1      ,    0          ] res falls under toxic & obscene & insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()\n",
    "\n",
    "# predict test dataset\n",
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create demo for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gradio jinja2\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('toxicity.h5')\n",
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
